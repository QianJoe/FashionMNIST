{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实战：FashionMNIST时装分类\n",
    "任务简介：\n",
    "- 这里的任务是对10个类别的“时装”图像进行分类，使用FashionMNIST数据集。 \n",
    "- FashionMNIST中数据的若干样例图，其中每个小图对应一个样本。\n",
    "- FashionMNIST数据集中包含已经预先划分好的训练集和测试集，其中训练集共60,000张图像，测试集共10,000张图像。\n",
    "- 每张图像均为单通道黑白图像，大小为28*28pixel，分属10个类别。\n",
    "\n",
    "0.导入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.配置训练环境和超参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先查看是否可以使用GPU\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置GPU，两种方式\n",
    "## 方案1：使用os.environ   这种之后用xxx.cuda()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'  # 这里可以是多块 0,1,2,3\n",
    "# 方案2：使用device，后续要使用GPU直接用xxx.to_device(device)\n",
    "# device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 配置超参\n",
    "batch_size = 256\n",
    "num_workers = 4  # cpu4个线程来读入数据，负责将batch加载到RAM\n",
    "lr = 1e-4  # 学习率  1*10^(-4)\n",
    "epochs = 20  # 20比较小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.数据的读入与加载\n",
    "- 不仅要读入数据，还要读数据进行必要的变换，\n",
    "- 比如说需要将图片统一为一致的大小，以便后续能够输入网络训练，\n",
    "- 一般用torchvision包来完成，这是PyTorch官方用于图像处理的工具库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先设置数据变换\n",
    "from torchvision import transforms\n",
    "img_size = 28  # 因为要处理的图像大小为 28*28  单通道，灰度图\n",
    "# 图像预处理\n",
    "# Compose把多个步骤整合到一起：\n",
    "# ToTensor()能够把灰度范围从0-255变换到0-1之间\n",
    "# 后面的transform.Normalize()则把0-1变换到(-1,1)\n",
    "# transform.ToTensor(),\n",
    "# transform.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "# Normalize:image=(image-mean)/std\n",
    "# 其中mean和std分别通过(0.5,0.5,0.5)和(0.5,0.5,0.5)进行指定\n",
    "# 将ToTensor()转换的(0, 1)变成(0-0.5)/0,5 = -1  (1-0.5)/0.5=1\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # 图片格式\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取方式一，用自带的\n",
    "# from torchvision import datasets\n",
    "# train_data = datasets.FashionMNIST(root='./', train=True, download=True, transform=data_transform)\n",
    "# test_data = datasets.FashionMNIST(root='./', train=False, download=True, transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n"
     ]
    }
   ],
   "source": [
    "# 读取方式二，读入csv格式的数据，自行构建Dataset类\n",
    "train_df = pd.read_csv('./MNIST/fashion-mnist_train.csv')\n",
    "test_df = pd.read_csv('./MNIST/fashion-mnist_test.csv')\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMDataset(Dataset):\n",
    "    # df:dataframe\n",
    "    def __init__(self, df, transform=None):\n",
    "        # python类直接通过这个就可以实现\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        # 取df的所有行第1列到最后的内容，第0列是label，从后面开始才是图的内容\n",
    "        self.images = df.iloc[:,1:].values.astype(np.uint8)  # 专门的图像格式\n",
    "        self.labels = df.iloc[:,0].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 一条一条的读\n",
    "        每一条都是784,reshape成28*28*1\n",
    "        image = self.images[idx].reshape(28, 28, 1) #32*32的灰度图转为28*28 单一通道的\n",
    "        label = int(self.labels[idx])\n",
    "        # 对imgae和label进行处理\n",
    "        if self.transform is not None: #如果转换函数非空\n",
    "            image = self.transform(image) #进行数据转换\n",
    "        else:\n",
    "            # /255是归一化为0-1，方便处理\n",
    "            image = torch.tensor(image/255, dtype=torch.float)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化\n",
    "train_data = FMDataset(train_df, data_transform)\n",
    "test_data = FMDataset(test_df, data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建好Dataset后，就可以使用DataLoader来按批次读入数据\n",
    "# data_set：构建好的样本\n",
    "# batch_size：样本是按“批”读入的，batch_size就是每次读入的样本数 这里为256\n",
    "# num_workers：有多少个进程用于读取数据\n",
    "# shuffle：是否将读入的数据打乱\n",
    "# drop_last：对于样本最后一部分没有达到批次数(就是不满一个batch的数量)的样本，使其不再参与训练\n",
    "# pin_memory：锁页内存，设置为True，直接将内存的张量转义到GPU的显存速度会快，如果显存爆炸，就设置为False\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, num_workers=num_workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28]) torch.Size([256])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQfUlEQVR4nO3dX2zVdZrH8c9D+U9RKWyxwbrogLAqLm7QLLIuLpM1Djc6F7PRC+MmZpmLMTrJXKxxL4bEG7PZmXEuNpN0VjPMZtbR6BgxGh1jTMxEMfxJQdiCZVGgUEAEtEBBWp696HFStL/nW85/+32/kuac/p7z7Xl60k9/55zv+f2+5u4CMPFNanQDAOqDsAOZIOxAJgg7kAnCDmRicj3vzMx4678MkybF/5MvXrxYp06+KdVbJDUT1NLSUvbPlqShoaGKxn9bubuNtb2isJvZPZJ+KalF0n+5+1OV/DyMbcaMGWH9zJkzderkm2bOnFn22OHh4bA+e/bssJ76Z/Hpp59edk8TWdn/ls2sRdJ/SvqepBslPWBmN1arMQDVVclr9tsl7XX3fe7+paTfS7q3Om0BqLZKwr5A0sFR3/eVtl3CzNaZ2RYz21LBfQGoUCWv2cd6E+AbL6LcvUtSl8QbdEAjVbJn75PUOer7ayQdrqwdALVSSdg3S1psZteZ2VRJ90vaWJ22AFRb2U/j3X3IzB6R9KZGpt6edfddVessI08//XRYf+yxx8L6gQMHCmutra3h2La2trD+zjvvhPWVK1eG9Wha8P333w/H9vT0hPVZs2aF9UcffbSwlpr2m4gqmmd399clvV6lXgDUEB+XBTJB2IFMEHYgE4QdyARhBzJB2IFM1PV4dozttttuC+tbt24N69Hx7P39/eHYjo6OsJ6ap3/ttdfC+uLFiwtrAwMD4dgXXnghrC9btiysR79bX19fOHYiYs8OZIKwA5kg7EAmCDuQCcIOZIKwA5lg6q0JLF26NKwfPHgwrH/22WeFtV274qOO77///rCeOkPryZMny65PmzYtHPvkk0+G9T179oT13t7ewhpTbwAmLMIOZIKwA5kg7EAmCDuQCcIOZIKwA5lgnr0O7r777rA+Z86csP7888+H9Wg10ylTpoRjU8s9X3HFFRWNj+zYsSOsX3PNNWE99bulVoHNDXt2IBOEHcgEYQcyQdiBTBB2IBOEHcgEYQcywTx7Hdx5551hfXBwMKwvWrQorEfz7MePHw/Hpk413dLSEtZTp5qePn16Ye3KK68Mx27fvj2sp+bZP//887Cem4rCbmafSBqQNCxpyN1XVKMpANVXjT37P7h7vPsA0HC8ZgcyUWnYXdIfzWyrma0b6wZmts7MtpjZlgrvC0AFKn0av8rdD5tZu6S3zGy3u787+gbu3iWpS5LMrPidJAA1VdGe3d0Ply6PSXpZ0u3VaApA9ZUddjObZWazv7ou6W5JO6vVGIDqquRp/HxJL5vZVz/nf9z9jap0NcGkzgufOq5706ZNYT2ax7/lllvCsanj0dvb28N6d3d3WF+9enVhLTrfvSRduHAhrKfOaT9//vywnpuyw+7u+yT9dRV7AVBDTL0BmSDsQCYIO5AJwg5kgrADmeAQ1zpITSGdP38+rKemmHbv3l1Yu+GGG8KxbW1tYX3SpHh/sGTJkrA+derUwtq5c+fCsalDWKPDZ6X0abBzw54dyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMMM9eB9ddd11Ynzt3bljv7OwM69GppKOaJE2bNi2sL1iwIKzv378/rA8NDRXWJk+O//zOnDkT1lOHyKZO0Z0b9uxAJgg7kAnCDmSCsAOZIOxAJgg7kAnCDmSCefY6OH36dFhPLas8Z86csL5r167C2tVXXx2OTR3vfvjw4bCeWk46mgtPHc+eEs3hS9K+ffsq+vkTDXt2IBOEHcgEYQcyQdiBTBB2IBOEHcgEYQcywTx7HaSWRU7Ns6fOG3/VVVcV1jZv3hyOXbhwYVhfv359WH/ppZfCejSXPm/evHDswYMHw/qMGTPCemoePjfJPbuZPWtmx8xs56htbWb2lpn1li7jT30AaLjxPI3/jaR7vrbtcUlvu/tiSW+XvgfQxJJhd/d3JZ342uZ7JW0oXd8g6b4q9wWgysp9zT7f3fslyd37zay96IZmtk7SujLvB0CV1PwNOnfvktQlSWYWn/0QQM2UO/V21Mw6JKl0eax6LQGohXLDvlHSQ6XrD0l6pTrtAKiV5NN4M3tO0l2S5plZn6SfSnpK0gtm9rCkA5J+UMsmv+3MLKy3tLSE9d7e3rAezbOvWbMmHJtaA33jxo1hPbV+e/Tzh4eHw7FffPFFWD979mxYT63fnptk2N39gYLSd6vcC4Aa4uOyQCYIO5AJwg5kgrADmSDsQCY4xLUOTp06FdZT01+ppY0PHTpUWIum5SRp27ZtYT1l7969Yb2tra2w1t/fH45NTb2lTJ06taLxEw17diAThB3IBGEHMkHYgUwQdiAThB3IBGEHMsE8ex2kTgV97bXXhvWZM2eG9cHBwcJa6jTWb7zxRlhP2bRpU1hfu3ZtYS21HHRqqetp06aF9fPnz4f13LBnBzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE8yz10HqmO9FixZV9POjpYu//PLLcGxPT09F971v376wHp1GO3Wq59QptlNLNh85ciSs54Y9O5AJwg5kgrADmSDsQCYIO5AJwg5kgrADmWCevQ4GBgbCeurc7inRfHNra2s49qOPPqrovlPndh8aGiqszZ49OxybWtI5tRR26nHPTXLPbmbPmtkxM9s5att6MztkZt2lr+IzFABoCuN5Gv8bSfeMsf0X7r689PV6ddsCUG3JsLv7u5JO1KEXADVUyRt0j5jZjtLT/DlFNzKzdWa2xcy2VHBfACpUbth/Jek7kpZL6pf0s6IbunuXu69w9xVl3heAKigr7O5+1N2H3f2ipF9Lur26bQGotrLCbmYdo779vqSdRbcF0ByS8+xm9pykuyTNM7M+ST+VdJeZLZfkkj6R9MMa9vitt3v37rCeOi986pj0aHxHR0dhTZLOnTsX1lNOnjwZ1qNj0lPz6Kne9u/fH9ZPnOB95dGSYXf3B8bY/EwNegFQQ3xcFsgEYQcyQdiBTBB2IBOEHcgEh7jWwfHjx8N66hDXCxcuhPVoeis1NrWkc0pfX19Yj+5/8uT4zy81NceSzJeHPTuQCcIOZIKwA5kg7EAmCDuQCcIOZIKwA5lgnr0OUoe4pk7HnFqaODol85kzZ8KxlUrNsw8ODhbWpk6dGo5dsmRJWN+zZ09Yx6XYswOZIOxAJgg7kAnCDmSCsAOZIOxAJgg7kAnm2ZtA6pjy66+/PqxHp4vevn17WT2NV+pY/blz5xbWbr755nBsf39/WL/11lvD+osvvlhYSx3nPxGxZwcyQdiBTBB2IBOEHcgEYQcyQdiBTBB2IBPMszeB6Hh0SVq1alVYj+a6b7rpprJ6Gq/UsspDQ0OFtdbW1nDs8uXLw/rp06fDeo5z6ZHknt3MOs3sHTPrMbNdZvZYaXubmb1lZr2lyzm1bxdAucbzNH5I0k/c/a8k/a2kH5nZjZIel/S2uy+W9HbpewBNKhl2d+93922l6wOSeiQtkHSvpA2lm22QdF+tmgRQuct6zW5mCyXdKukDSfPdvV8a+YdgZu0FY9ZJWldZmwAqNe6wm1mrpJck/djdvzCzcY1z9y5JXaWf4eU0CaBy45p6M7MpGgn679z9D6XNR82so1TvkHSsNi0CqIbknt1GduHPSOpx95+PKm2U9JCkp0qXr9SkwwwMDAyE9YULF4b1aHqrvX3MV1d/Nn369LCemlqbOXNm2fVTp06FY1OH9vb09IR1XGo8T+NXSXpQ0odm1l3a9oRGQv6CmT0s6YCkH9SmRQDVkAy7u/9JUtEL9O9Wtx0AtcLHZYFMEHYgE4QdyARhBzJB2IFMcIhrEzhw4EBY7+zsDOvRXLZ7/KHFWbNmhfXUPHtqOeno/idNivc1kyfHf54ff/xxWMel2LMDmSDsQCYIO5AJwg5kgrADmSDsQCYIO5AJ5tmbwHvvvRfW16xZE9aHh4cLa8eOxecUueOOO8L6q6++GtZbWlrCerQcdepsR6nPCPT19YV1XIo9O5AJwg5kgrADmSDsQCYIO5AJwg5kgrADmWCevQl88MEHYT06L7wUHxeemsteunRpWE/Ns6eOSY/mylPz6Kn60aNHwzouxZ4dyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMjGd99k5Jv5V0taSLkrrc/Zdmtl7Sv0j6tHTTJ9z99Vo1OpGl1hkfHBwM69H51VNz9IsXLw7rKa2trWWPvXDhQkX3feTIkYrG52Y8H6oZkvQTd99mZrMlbTWzt0q1X7j7f9SuPQDVMp712fsl9ZeuD5hZj6QFtW4MQHVd1mt2M1so6VZJX32+8xEz22Fmz5rZnIIx68xsi5ltqahTABUZd9jNrFXSS5J+7O5fSPqVpO9IWq6RPf/Pxhrn7l3uvsLdV1ShXwBlGlfYzWyKRoL+O3f/gyS5+1F3H3b3i5J+Len22rUJoFLJsNvIYVPPSOpx95+P2t4x6mbfl7Sz+u0BqJbxvBu/StKDkj40s+7StickPWBmyyW5pE8k/bAmHWbg0KFDYf3s2bNhvb29vbA2ZcqUcGx0qufxSI2P7n/u3Lnh2JMnT4Z1pt4uz3jejf+TpLEOimZOHfgW4RN0QCYIO5AJwg5kgrADmSDsQCYIO5AJS52ut6p3Zla/O5tAHnzwwbC+cuXKwlp3d3dhTZK6urrK6mm8Vq9eXVhbtmxZOLa3tzesv/nmm2X1NNG5+5jnD2fPDmSCsAOZIOxAJgg7kAnCDmSCsAOZIOxAJuo9z/6ppP2jNs2TdLxuDVyeZu2tWfuS6K1c1eztL939L8Yq1DXs37hzsy3Nem66Zu2tWfuS6K1c9eqNp/FAJgg7kIlGh722H8yuTLP21qx9SfRWrrr01tDX7ADqp9F7dgB1QtiBTDQk7GZ2j5ntMbO9ZvZ4I3ooYmafmNmHZtbd6PXpSmvoHTOznaO2tZnZW2bWW7occ429BvW23swOlR67bjNb26DeOs3sHTPrMbNdZvZYaXtDH7ugr7o8bnV/zW5mLZI+kvSPkvokbZb0gLv/b10bKWBmn0ha4e4N/wCGmf29pNOSfuvuN5e2/bukE+7+VOkf5Rx3/9cm6W29pNONXsa7tFpRx+hlxiXdJ+mf1cDHLujrn1SHx60Re/bbJe11933u/qWk30u6twF9ND13f1fSia9tvlfShtL1DRr5Y6m7gt6agrv3u/u20vUBSV8tM97Qxy7oqy4aEfYFkg6O+r5PzbXeu0v6o5ltNbN1jW5mDPPdvV8a+eORVLz2U2Mkl/Gup68tM940j105y59XqhFhH+v8WM00/7fK3f9G0vck/aj0dBXjM65lvOtljGXGm0K5y59XqhFh75PUOer7ayQdbkAfY3L3w6XLY5JeVvMtRX30qxV0S5fHGtzPnzXTMt5jLTOuJnjsGrn8eSPCvlnSYjO7zsymSrpf0sYG9PENZjar9MaJzGyWpLvVfEtRb5T0UOn6Q5JeaWAvl2iWZbyLlhlXgx+7hi9/7u51/5K0ViPvyP+fpH9rRA8FfV0vaXvpa1eje5P0nEae1l3QyDOihyXNlfS2pN7SZVsT9fbfkj6UtEMjwepoUG9/p5GXhjskdZe+1jb6sQv6qsvjxsdlgUzwCTogE4QdyARhBzJB2IFMEHYgE4QdyARhBzLx/3J4NrAnkOq7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# next是获取下一个项目\n",
    "# next(iterator[,default])\n",
    "# iterator ：要读取行的文件对象\n",
    "# default ：如果迭代器耗尽则返回此默认值。 如果没有给出此默认值，则抛出 StopIteration 异常\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape, labels.shape)\n",
    "# 展示第0个数据，第二个0为color\n",
    "plt.imshow(images[0][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.模型构建\n",
    "- 神经网络的构造：基于nn.Module\n",
    "    - __init__, forward\n",
    "- 神经网络是通过“层定义+层顺序”的方式构建起来的\n",
    "- 神经网络常见层\n",
    "    - nn.Conv2d, nn.MaxPool2d, nn.Linear, nn.ReLU,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用简单的 cnn\n",
    "# Module 类是 nn 模块里提供的一个模型构造类，\n",
    "# 是所有神经⽹网络模块的基类，我们可以继承它来定义我们想要的模型\n",
    "class Net(nn.Module):\n",
    "    # 声明Net模型有哪些类\n",
    "    def __init__(self):\n",
    "        # 调用Net父类Block的构造函数来进行必要的初始化。\n",
    "        # 这样在构造实例时还可以指定其他函数\n",
    "        super(Net, self).__init__()\n",
    "        # List/Dict中元素顺序并不代表其网络中的真实位置顺序，需要forward函数指定各个层的连接顺序\n",
    "        # 定义序贯模型\n",
    "        self.conv = nn.Sequential(\n",
    "            # 二维卷积\n",
    "            # in_channels:对于最初输入图片样本的通道数 in_channels \n",
    "            # 取决于图片的类型这里数据是灰色的通道就是1个，所以就传入1；如果是RGB的图，3通道，这里就传3\n",
    "            # out_channels:卷积完成之后，输出的通道数 out_channels 取决于过滤器的数量，\n",
    "            # 这里的 out_channels 设置的就是过滤器的数目。\n",
    "            # 对于第二层或者更多层的卷积，此时的 in_channels 就是上一层的 out_channels ， out_channels 还是取决于过滤器数目\n",
    "            # kernel_size,  卷积核设置为5*5\n",
    "            # stride=1,\n",
    "            # padding=0,\n",
    "            # dilation=1,\n",
    "            # groups=1,\n",
    "            # bias=True,\n",
    "            # padding_mode='zeros',\n",
    "            nn.Conv2d(1, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            # kernel_size ：表示做最大池化的窗口大小，可以是单个值（单*单），也可以是tuple元组\n",
    "            # stride ：步长，可以是单个值（向右滑动2个窗口，向下滑动2个窗口），也可以是tuple元组\n",
    "            # padding ：填充，可以是单个值，也可以是tuple元组\n",
    "            # dilation ：控制窗口中元素步幅\n",
    "            # return_indices ：布尔类型，返回最大值位置索引\n",
    "            # ceil_mode ：布尔类型，为True，用向上取整的方法，计算输出形状；默认是向下取整。\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3),\n",
    "            # 第二层卷积的in_channels就是第一层的out_channels\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            # Dropout是为了防止过拟合而设置的\n",
    "            # Dropout顾名思义有丢掉的意思\n",
    "            # nn.Dropout(p = 0.3) # 表示每个神经元有0.3的可能性不被激活\n",
    "            # Dropout只能用在训练部分而不能用在测试部分\n",
    "            # Dropout一般用在全连接神经网络映射层之后，如代码的nn.Linear(20, 30)之后\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        # 全连接层\n",
    "        self.fc = nn.Sequential(\n",
    "            # in_features：输入的神经元个数\n",
    "            # out_features：输出神经元个数\n",
    "            # bias=True：是否包含偏置\n",
    "            # 其实Linear其实就是对输入X(n*i)执行了一个线性变换，即：\n",
    "            # y = XW + b 其实W是模型要学习的参数，W的维度为i*o，b是o维的向量偏置，n微输入向量的行数\n",
    "            # （例如，一次输入10个样本，即batch_size为10，则n=10），i为输入神经元的个数（例如样本的特征书为5，则i=5）\n",
    "            # o为输出神经元的个数\n",
    "            # 例如，定义线性层，我们的输入特征为5，所以in_feature=5，\n",
    "            # 我们想让下一层的神经元个数为10，所以out_feature=10，则模型参数为：W(5 × 10)\n",
    "            # 这里输入特征数为64*4*4，输出特征数为512\n",
    "            # 本来说32*32的特征（32*32的大小）\n",
    "            nn.Linear(64*4*4, 512),\n",
    "            # F.relu(input)一般在forward函数里面使用，这个一般在初始化的时候使用，\n",
    "            # 例如F.relu(self.fc(x))，其他的层也可以这样用\n",
    "            nn.ReLU(),  \n",
    "            # 10是有10类，所以设置为10\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        # 可能还有其他层如隐藏层hidden，输出层output\n",
    "        # self.hidden = nn.Linear(784, 256) # 隐藏层\n",
    "        # self.act = nn.ReLU()\n",
    "        # self.output = nn.Linear(256, 10)  # 输出层\n",
    "    \n",
    "    # 前馈，排列\n",
    "    # 定义模型的前向计算，即如何根据输入x计算返回所需要的模型输出\n",
    "    # 数据如何在层之间流动\n",
    "    def forward(self, x):\n",
    "        # 先把x传入到卷积里面\n",
    "        x = self.conv(x)  # conv和fc这些都是自己在__init__ 定义的\n",
    "        # view就是改变shape，拉平，便于全连接层的操作\n",
    "        x = x.view(-1, 64*4*4)\n",
    "        # 传入全连接层\n",
    "        x = self.fc(x)  # 变成了10维的数据用于输出\n",
    "        # 如果给的是torch.randn(1, 1, 32, 32)表示batch_size=1， 1通道（灰度图像），图片尺寸：32x32\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![conv2d](./conv.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "model = Net()\n",
    "model = model.cuda()\n",
    "# model = nn.DataParallel(model).cuda()  # 多卡训练时的写法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.损失函数\n",
    "- 损失函数常用的操作\n",
    "    - backward()\n",
    "- 使用nn自带的CrossEntropy损失\n",
    "- PyTorch会自动把整型的label转为one-hot型，用于计算CE loss。这里需要确保label是从0开始的，同时模型不加softmax层(使用logits计算)，所以PyTorch训练中各个部分不是独立的，需要通盘考虑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# 可以加权重，对第2个惩罚两次\n",
    "# criterion = nn.CrossEntropyLoss(weight=[1, 1, 2, 1, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.设定优化器\n",
    "使用Adam优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.训练与测试（验证）\n",
    "各自封装成函数，方便后续调用\n",
    "关注两者的主要区别：\n",
    "- 模型状态设置\n",
    "- 是否需要初始化优化器\n",
    "- 是否需要将loss传回到网络\n",
    "- 是否需要每步更新optimizer\n",
    "\n",
    "训练与评估\n",
    "- 模型状态设置\n",
    "    - model.train(), model.eval()\n",
    "- 训练流程：读取、转换、梯度清零、输入、计算损失、反向传播、参数更新\n",
    "- 验证流程：读取、 转换、输入、计算损失、计算指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    # model.train()的作用是启用 Batch Normalization 和 Dropout\n",
    "    # 如果模型中有BN层(Batch Normalization）和Dropout，需要在训练时添加model.train()。\n",
    "    # model.train()是保证BN层能够用到每一批数据的均值和方差。\n",
    "    # 对于Dropout，model.train()是随机取一部分网络连接来训练更新参数。\n",
    "    model.train()\n",
    "    # 如果模型中有BN层(Batch Normalization）和Dropout，在测试时添加model.eval()。\n",
    "    # model.eval()是保证BN层能够用全部训练数据的均值和方差，即测试过程中要保证BN层的均值和方差不变。\n",
    "    # 对于Dropout，model.eval()是利用到了所有网络连接，即不进行随机舍弃神经元。\n",
    "    # model.eval()\n",
    "    train_loss = 0\n",
    "    for data, label in train_loader:   # for i, (data, label) in enumerate(train_loader):\n",
    "        # data.cuda()就将其转换为GPU的张量类型\n",
    "        data, label = data.cuda(), label.cuda()\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        # 训练集上得到结果\n",
    "        output = model(data)\n",
    "        loss = criterion(output, label) # 使用预定义的criterion计算损失函数\n",
    "        loss.backward() # 将loss反向传播回网络\n",
    "        optimizer.step() # 使用优化器更新模型参数\n",
    "        # data.size(0) data的第1维为为256 一个batch_size为256\n",
    "        train_loss += loss.item() * data.size(0) # 每一批样本的损失值之和\n",
    "    train_loss = train_loss / len(train_loader.dataset)  # 加权平均数\n",
    "    print('Epoch:{} \\t Training Loss:{:.6f}'.format(epoch, train_loss))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    gt_labels = []\n",
    "    pred_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            data, label = data.cuda(), label.cuda()\n",
    "            output = model(data)\n",
    "            # 每一维列的最大值的下标\n",
    "            # 因为这里是10个类别，要看他哪一个是1，得到那个类别\n",
    "            preds = torch.argmax(output, 1)\n",
    "            \n",
    "            # 真实的标签\n",
    "            # 一次传入256长得list到一个list里面\n",
    "            # 这样pred_labels就是n*256\n",
    "            gt_labels.append(label.cpu().data.numpy())\n",
    "            # print(gt_labels.shape)\n",
    "            # 算出来的标签\n",
    "            # 一次传入256长得list到一个list里面\n",
    "            # 这样pred_labels就是n*256\n",
    "            pred_labels.append(preds.cpu().data.numpy())\n",
    "            loss = criterion(output, label)\n",
    "            val_loss += loss.item()*data.size(0)\n",
    "    val_loss = val_loss / len(test_loader.dataset)\n",
    "    # print(len(gt_labels), len(pred_labels))\n",
    "    # 这里拼接成一维\n",
    "    gt_labels, pred_labels = np.concatenate(gt_labels), np.concatenate(pred_labels)\n",
    "    # print('gt_labels:', gt_labels, 'pred_labels:',pred_labels)\n",
    "    acc = np.sum(gt_labels == pred_labels) / len(pred_labels)\n",
    "    print('Epoch:{} \\t Validation Loss:{:.6f}, ACC:{:6f}'.format(epoch, val_loss, acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 \t Training Loss:0.059837\n",
      "Epoch:1 \t Validation Loss:0.273478, ACC:0.931800\n",
      "Epoch:2 \t Training Loss:0.056281\n",
      "Epoch:2 \t Validation Loss:0.288382, ACC:0.928000\n",
      "Epoch:3 \t Training Loss:0.058180\n",
      "Epoch:3 \t Validation Loss:0.277755, ACC:0.929200\n",
      "Epoch:4 \t Training Loss:0.057567\n",
      "Epoch:4 \t Validation Loss:0.290397, ACC:0.927800\n",
      "Epoch:5 \t Training Loss:0.054568\n",
      "Epoch:5 \t Validation Loss:0.284727, ACC:0.929800\n",
      "Epoch:6 \t Training Loss:0.056489\n",
      "Epoch:6 \t Validation Loss:0.285244, ACC:0.930000\n",
      "Epoch:7 \t Training Loss:0.054096\n",
      "Epoch:7 \t Validation Loss:0.282660, ACC:0.932200\n",
      "Epoch:8 \t Training Loss:0.054379\n",
      "Epoch:8 \t Validation Loss:0.285901, ACC:0.932200\n",
      "Epoch:9 \t Training Loss:0.053121\n",
      "Epoch:9 \t Validation Loss:0.290915, ACC:0.928200\n",
      "Epoch:10 \t Training Loss:0.055566\n",
      "Epoch:10 \t Validation Loss:0.294653, ACC:0.930600\n",
      "Epoch:11 \t Training Loss:0.051960\n",
      "Epoch:11 \t Validation Loss:0.287186, ACC:0.930300\n",
      "Epoch:12 \t Training Loss:0.054744\n",
      "Epoch:12 \t Validation Loss:0.289867, ACC:0.931800\n",
      "Epoch:13 \t Training Loss:0.049734\n",
      "Epoch:13 \t Validation Loss:0.286606, ACC:0.931500\n",
      "Epoch:14 \t Training Loss:0.055359\n",
      "Epoch:14 \t Validation Loss:0.281526, ACC:0.929600\n",
      "Epoch:15 \t Training Loss:0.055891\n",
      "Epoch:15 \t Validation Loss:0.287419, ACC:0.927000\n",
      "Epoch:16 \t Training Loss:0.056429\n",
      "Epoch:16 \t Validation Loss:0.289228, ACC:0.930900\n",
      "Epoch:17 \t Training Loss:0.051010\n",
      "Epoch:17 \t Validation Loss:0.293492, ACC:0.930200\n",
      "Epoch:18 \t Training Loss:0.052252\n",
      "Epoch:18 \t Validation Loss:0.301825, ACC:0.930700\n",
      "Epoch:19 \t Training Loss:0.052378\n",
      "Epoch:19 \t Validation Loss:0.296794, ACC:0.931100\n",
      "Epoch:20 \t Training Loss:0.051405\n",
      "Epoch:20 \t Validation Loss:0.308859, ACC:0.926800\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    train(epoch)\n",
    "    val(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 17 13:44:35 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 430.40       Driver Version: 430.40       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 36%   42C    P2    62W / 250W |   1227MiB / 11019MiB |      6%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 22%   26C    P8     5W / 250W |     10MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# 查看GPU信息\n",
    "gpu_info = !nvidia-smi -i 0,1\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './FashionModel.pkl'\n",
    "torch.save(model, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
